{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python script uses the YouTube Data API to extract comments from a specific YouTube video and filters them to retain only those written in Telugu (using Unicode character range detection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:38:08.874395Z",
     "iopub.status.busy": "2025-04-22T06:38:08.871188Z",
     "iopub.status.idle": "2025-04-22T06:38:09.513711Z",
     "shell.execute_reply": "2025-04-22T06:38:09.512708Z",
     "shell.execute_reply.started": "2025-04-22T06:38:08.874358Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 146 Telugu comments from video C3o_UaQb-Es to S_T_042_comments.xlsx\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# 1. Configuration\n",
    "# Set your YouTube Data API key (replace with your actual key)\n",
    "API_KEY = 'AIzaSyCLJP2eVGlLn2Cuig0n34PVGzr4#######'\n",
    "\n",
    "# Specify the YouTube video ID to extract comments from\n",
    "# Example format: 'dQw4w9WgXcQ'\n",
    "VIDEO_ID = 'C3o_UaQb-Es'\n",
    "\n",
    "# Define the output Excel file name where the filtered comments will be saved\n",
    "EXCEL_FILE = 'S_T_001_comments.xlsx'\n",
    "\n",
    "# 2. Initialize YouTube client\n",
    "youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
    "\n",
    "# 3. Paginate through comment threads for one video\n",
    "comments = []\n",
    "next_page_token = None\n",
    "\n",
    "while True:\n",
    "    response = youtube.commentThreads().list(\n",
    "        part='snippet',\n",
    "        videoId=VIDEO_ID,             # ‚Üê Target single video\n",
    "        maxResults=100,\n",
    "        pageToken=next_page_token,\n",
    "        textFormat='plainText'\n",
    "    ).execute()\n",
    "    \n",
    "    for item in response.get('items', []):\n",
    "        tlc = item['snippet']['topLevelComment']\n",
    "        comment_id = tlc['id']\n",
    "        snippet    = tlc['snippet']\n",
    "        text       = snippet['textDisplay']\n",
    "        \n",
    "        # 4. Filter for Telugu characters\n",
    "        if re.search(r'[\\u0C00-\\u0C7F]', text):\n",
    "            comments.append({\n",
    "                'comment_id':   comment_id,\n",
    "                'author':       snippet['authorDisplayName'],\n",
    "                'published_at': snippet['publishedAt'],\n",
    "                'text':         text.replace('\\n', ' ')\n",
    "            })\n",
    "    \n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    if not next_page_token:\n",
    "        break\n",
    "\n",
    "# 5. Save to Excel\n",
    "df = pd.DataFrame(comments)\n",
    "df.to_excel(EXCEL_FILE , index=False, sheet_name='TeluguComments') \n",
    "\n",
    "print(f\"Saved {len(df)} Telugu comments from video {VIDEO_ID} to {EXCEL_FILE}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
